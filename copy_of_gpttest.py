# -*- coding: utf-8 -*-
"""Copy of gpttest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F93Rw3rTQh_ZooEsQj6J6qDCvFww6LtA
"""

import os
import shutil
from PyPDF2 import PdfReader
import pytesseract
from pdf2image import convert_from_path
from pathlib import Path

# Paths to the input and output directories (replace these with your actual paths)
input_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/documents"  # Folder containing both images and PDFs
afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib"
non_afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/non-afib"

# Ensure output folders exist
os.makedirs(afib_folder_path, exist_ok=True)
os.makedirs(non_afib_folder_path, exist_ok=True)

# Helper function to extract text from a PDF file
def extract_text_from_pdf(pdf_path):
    try:
        # Try to extract text using PyPDF2
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        if text.strip():  # If text is successfully extracted
            return text
    except Exception as e:
        print(f"Error reading PDF {pdf_path}: {e}")

    # If PyPDF2 fails, fallback to OCR using pytesseract
    try:
        images = convert_from_path(pdf_path)
        text = ""
        for image in images:
            text += pytesseract.image_to_string(image)
        return text
    except Exception as e:
        print(f"Error performing OCR on PDF {pdf_path}: {e}")
        return ""

# Process each JPEG image in the folder
for file in os.listdir(input_folder_path):
    if not file.endswith(".jpeg"):
        continue

    # Extract the base filename to find the corresponding PDF
    base_name = Path(file).stem  # Removes file extension
    pdf_file = f"{base_name}_report.pdf"
    pdf_path = os.path.join(input_folder_path, pdf_file)

    if not os.path.exists(pdf_path):
        print(f"PDF report not found for image {file}")
        continue

    # Extract text from the corresponding PDF
    pdf_text = extract_text_from_pdf(pdf_path)

    # Check for "Rhythm" and "Atrial Fibrillation" in the extracted text
    if "Atrial Fibrillation" in pdf_text or "atrial fibrillation" in pdf_text:
        target_folder = afib_folder_path
    elif "Rhythm" in pdf_text or "rhythm" in pdf_text:
        target_folder = non_afib_folder_path
    else:
        # If neither is found, skip the image
        print(f"Skipping {file}: No relevant text found in PDF.")
        continue

    # Move the image to the appropriate folder
    source_path = os.path.join(input_folder_path, file)
    destination_path = os.path.join(target_folder, file)
    shutil.move(source_path, destination_path)
    print(f"Moved {file} to {target_folder}")

!pip install pytesseract
!pip install pdf2image
!pip install PyPDF2

!pip install poppler-utils

# Install required packages
!pip install PyPDF2 pytesseract pdf2image
!apt-get install -y poppler-utils tesseract-ocr

# Import required libraries
import os
import shutil
from PyPDF2 import PdfReader
import pytesseract
from pdf2image import convert_from_path
from pathlib import Path

# Define paths
input_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/documents"  # Folder containing both images and PDFs
afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib"
non_afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/non-afib"

error_log_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/error_log.txt"

# Ensure output folders exist
os.makedirs(afib_folder_path, exist_ok=True)
os.makedirs(non_afib_folder_path, exist_ok=True)

# Helper function to extract text from a PDF file
def extract_text_from_pdf(pdf_path):
    try:
        # Try to extract text using PyPDF2
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        if text.strip():
            return text
    except Exception as e:
        print(f"Error reading PDF {pdf_path}: {e}")

    # Fallback to OCR using pytesseract
    try:
        images = convert_from_path(pdf_path)
        text = ""
        for image in images:
            text += pytesseract.image_to_string(image)
        return text
    except Exception as e:
        print(f"Error performing OCR on PDF {pdf_path}: {e}")
        return None

# Process each JPEG image in the folder
with open(error_log_path, "w") as error_log:
    for file in os.listdir(input_folder_path):
        if not file.endswith(".jpeg"):
            continue

        # Extract the base filename to find the corresponding PDF
        base_name = Path(file).stem
        pdf_file = f"{base_name}_report.pdf"
        pdf_path = os.path.join(input_folder_path, pdf_file)

        if not os.path.exists(pdf_path):
            error_log.write(f"PDF report not found for image {file}\n")
            print(f"PDF report not found for image {file}")
            continue

        # Extract text from the corresponding PDF
        pdf_text = extract_text_from_pdf(pdf_path)

        if not pdf_text:
            error_log.write(f"Skipping {file}: OCR failed for PDF {pdf_path}\n")
            print(f"Skipping {file}: OCR failed for PDF {pdf_path}")
            continue

        # Check for "Rhythm" and "Atrial Fibrillation" in the extracted text
        if "Atrial Fibrillation" in pdf_text or "atrial fibrillation" in pdf_text:
            target_folder = afib_folder_path
        elif "Rhythm" in pdf_text or "rhythm" in pdf_text:
            target_folder = non_afib_folder_path
        else:
            # Skip if no relevant text is found
            error_log.write(f"Skipping {file}: No relevant text found in PDF {pdf_path}\n")
            print(f"Skipping {file}: No relevant text found in PDF {pdf_path}")
            continue

        # Move the image to the appropriate folder
        source_path = os.path.join(input_folder_path, file)
        destination_path = os.path.join(target_folder, file)
        shutil.move(source_path, destination_path)
        print(f"Moved {file} to {target_folder}")

# Print location of error log
print(f"Error log saved at: {error_log_path}")

import torch
from PIL import Image
from transformers import AutoProcessor, AutoModelForVision2Seq
from transformers.image_utils import load_image

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Load images
image1 = load_image("https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg")
image2 = load_image("https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg")

# Initialize processor and model
processor = AutoProcessor.from_pretrained("HuggingFaceTB/SmolVLM-Instruct")
model = AutoModelForVision2Seq.from_pretrained(
    "HuggingFaceTB/SmolVLM-Instruct",
    torch_dtype=torch.bfloat16,
    _attn_implementation="flash_attention_2" if DEVICE == "cuda" else "eager",
).to(DEVICE)

# Create input messages
messages = [
    {
        "role": "user",
        "content": [
            {"type": "image"},
            {"type": "image"},
            {"type": "text", "text": "Can you describe the two images?"}
        ]
    },
]

# Prepare inputs
prompt = processor.apply_chat_template(messages, add_generation_prompt=True)
inputs = processor(text=prompt, images=[image1, image2], return_tensors="pt")
inputs = inputs.to(DEVICE)

# Generate outputs
generated_ids = model.generate(**inputs, max_new_tokens=500)
generated_texts = processor.batch_decode(
    generated_ids,
    skip_special_tokens=True,
)

print(generated_texts[0])
"""
Assistant: The first image shows a green statue of the Statue of Liberty standing on a stone pedestal in front of a body of water.
The statue is holding a torch in its right hand and a tablet in its left hand. The water is calm and there are no boats or other objects visible.
The sky is clear and there are no clouds. The second image shows a bee on a pink flower.
The bee is black and yellow and is collecting pollen from the flower. The flower is surrounded by green leaves.
"""

import os
import json

# Define paths to afib and non-afib folders
afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib"
non_afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/non-afib"


# Function to create JSON response
def generate_ecg_json(image_name, folder_type):
    # Example logic to determine values (you can replace this with actual ChatGPT integration later)
    diagnosis = "AFIB" if folder_type == "afib" else "NON-AFIB"
    response = {
        "Diagnosis": diagnosis,
        "Rhythm Regularity": "Irregularly Irregular" if diagnosis == "AFIB" else "Regular",
        "P Waves": "Absent" if diagnosis == "AFIB" else "Present",
        "Baseline Activity": "Fibrillatory Waves" if diagnosis == "AFIB" else "Normal",
        "Ventricular Rate": "Tachycardic" if diagnosis == "AFIB" else "Normal",
        "QRS Complex Morphology": "Variable" if diagnosis == "AFIB" else "Constant",
        "PR Interval": "Not Measurable" if diagnosis == "AFIB" else "Normal"
    }
    return response

# Process each folder
for folder_path, folder_type in [(afib_folder_path, "afib"), (non_afib_folder_path, "non-afib")]:
    # Iterate over each image in the folder
    for image_file in os.listdir(folder_path):
        if not image_file.endswith(".jpeg"):  # Skip non-image files
            continue

        # Generate JSON response
        response = generate_ecg_json(image_file, folder_type)

        # Save JSON to file
        json_file_name = os.path.splitext(image_file)[0] + ".json"  # Replace .jpeg with .json
        json_file_path = os.path.join(folder_path, json_file_name)
        with open(json_file_path, "w") as json_file:
            json.dump(response, json_file, indent=4)

        print(f"Created JSON file for {image_file}: {json_file_path}")

import os
import json
import pandas as pd

# Define paths to afib and non-afib folders
afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib"
non_afib_folder_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/non-afib"

# Define the expected responses
expected_afib = {
    "Diagnosis": "AFIB",
    "Rhythm Regularity": "Irregularly Irregular",
    "P Waves": "Absent or not discernible",
    "Baseline Activity": "Fibrillatory Waves",
    "Ventricular Rate": "Tachycardic at (90–200 bpm)",
    "QRS Complex Morphology": "Constant",
    "PR Interval": "Not Measurable"
}

# Statistics containers
afib_results = []
non_afib_results = []

# Function to compare LLM response with expected values
def compare_responses(llm_response, expected_response, is_afib=True):
    result = {"File": llm_response.get("File", "Unknown")}
    correct_count = 0
    total_features = len(expected_response)

    for key, expected_value in expected_response.items():
        actual_value = llm_response.get(key, "Missing")
        if key == "P Waves" and is_afib:  # Handle special case for "P Waves"
            if actual_value in expected_value:
                result[key] = "Correct"
                correct_count += 1
            else:
                result[key] = f"Wrong (Expected: {expected_value}, Found: {actual_value})"
        elif actual_value == expected_value:
            result[key] = "Correct"
            correct_count += 1
        else:
            result[key] = f"Wrong (Expected: {expected_value}, Found: {actual_value})"

    result["Correct Features"] = correct_count
    result["Total Features"] = total_features
    result["Accuracy"] = correct_count / total_features
    return result

# Analyze AFIB folder
for file in os.listdir(afib_folder_path):
    if file.endswith(".json"):
        with open(os.path.join(afib_folder_path, file), "r") as f:
            llm_response = json.load(f)
        llm_response["File"] = file
        afib_results.append(compare_responses(llm_response, expected_afib, is_afib=True))

# Analyze NON-AFIB folder
for file in os.listdir(non_afib_folder_path):
    if file.endswith(".json"):
        with open(os.path.join(non_afib_folder_path, file), "r") as f:
            llm_response = json.load(f)
        llm_response["File"] = file
        # Check if diagnosis is correct and at least one other feature differs
        diagnosis_correct = llm_response.get("Diagnosis") == "NON-AFIB"
        differing_features = [
            key for key, expected_value in expected_afib.items()
            if llm_response.get(key) != expected_value and key != "Ventricular Rate"
        ]
        result = {
            "File": file,
            "Diagnosis Correct": diagnosis_correct,
            "Differing Features Count": len(differing_features),
            "Differing Features": differing_features,
            "Valid": diagnosis_correct and len(differing_features) > 0
        }
        non_afib_results.append(result)

# Convert results to DataFrames for analysis
afib_df = pd.DataFrame(afib_results)
non_afib_df = pd.DataFrame(non_afib_results)

# Calculate overall statistics
afib_accuracy = afib_df["Accuracy"].mean() * 100
non_afib_valid_count = non_afib_df["Valid"].sum()

# Print detailed statistics
print("\nAFIB Detailed Statistics:")
print(afib_df)

print("\nNON-AFIB Detailed Statistics:")
print(non_afib_df)

# Summarize results
summary = {
    "AFIB Cases Analyzed": len(afib_results),
    "AFIB Average Accuracy (%)": afib_accuracy,
    "NON-AFIB Cases Analyzed": len(non_afib_results),
    "NON-AFIB Valid Cases Count": non_afib_valid_count,
    "NON-AFIB Valid Percentage": (non_afib_valid_count / len(non_afib_results)) * 100 if non_afib_results else 0
}

print("\nSummary:")
print(summary)

!pip install transformers accelerate torch torchvision requests pillow

from huggingface_hub import login

# Use your Hugging Face token
login("")

import requests
import torch
from PIL import Image
from transformers import AutoModelForVision2Seq, AutoProcessor

# Model ID
model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"

# Load model and processor
model = AutoModelForVision2Seq.from_pretrained(
    model_id,
    torch_dtype=torch.float16,  # Use bfloat16 if your GPU supports it
    device_map="auto",         # Automatically assign model to GPU if available
)
processor = AutoProcessor.from_pretrained(model_id)

# Load image (replace with your ECG image)
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg"
image = Image.open(requests.get(url, stream=True).raw)

# Define the prompt
messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": "Describe the image "}
    ]}
]
input_text = processor.apply_chat_template(messages, add_generation_prompt=True)

# Prepare inputs
inputs = processor(
    image,
    input_text,
    add_special_tokens=False,
    return_tensors="pt"
).to(model.device)

# Generate output
outputs = model.generate(**inputs, max_new_tokens=30)
result = processor.decode(outputs[0])

# Print result
print(result)

# Load model directly
from transformers import AutoProcessor, AutoModelForImageTextToText

processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-72B")
model = AutoModelForImageTextToText.from_pretrained("Qwen/Qwen2-VL-72B")

!pip install huggingface_hub

# Define the image path and the accompanying text prompt
image_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib/151901_ecg_1.jpeg"  # Replace with the actual path to your image
prompt = "Describe the image."

import base64

# Read the image file and encode it in base64
with open(image_path, "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode("utf-8")

# Create the payload with the image and text prompt
messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image",
                "image": {
                    "url": f"data:image/jpeg;base64,{image_base64}"
                }
            },
            {
                "type": "text",
                "text": prompt
            }
        ]
    }
]

import base64

# Read the image and encode it
image_path = "/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/afib/151901_ecg_1.jpeg"  # Replace with your image path
with open(image_path, "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode("utf-8")

import os
import pandas as pd
import shutil

def categorize_ecg_images(excel_path, image_folder, afib_folder, sinus_rhythm_folder, abnormal_folder):
    # Load the Excel file
    df = pd.read_csv(excel_path)

    # Iterate over each row in the DataFrame
    for _, row in df.iterrows():
        study_id = row['Study ID']

        # Loop through ECGs 1 to 6
        for ecg_number in range(1, 7):
            diagnosis_column = f'Diagnosis ECG {ecg_number}'

            # Check if the diagnosis column exists and has a valid value
            if diagnosis_column in df.columns and pd.notna(row[diagnosis_column]):
                diagnosis = row[diagnosis_column]
                ecg_image_name = f"{study_id}_ecg_{ecg_number}.jpeg"
                image_path = os.path.join(image_folder, ecg_image_name)

                # Determine the target folder based on the diagnosis
                if diagnosis == 'A. Fib':
                    target_folder = afib_folder
                elif diagnosis == 'Sinus Rhythm':
                    target_folder = sinus_rhythm_folder
                elif diagnosis == 'Abnormal (not A. Fib)':
                    target_folder = abnormal_folder
                else:
                    continue  # Skip if diagnosis is invalid

                # Move the image if it exists
                if os.path.exists(image_path):
                    target_path = os.path.join(target_folder, ecg_image_name)
                    shutil.move(image_path, target_path)
                    print(f"Moved {ecg_image_name} to {target_folder}")
                else:
                    print(f"Image {ecg_image_name} not found in {image_folder}")

# Example usage
excel_path = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V2-dataset-nonretracted/AIECGAFib-ECG_DATA_LABELS_2024-12-07_1740.csv'  # Path to the Excel file
images_path = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V2-dataset-nonretracted/documents'  # Path to the folder containing images
afib_folder = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V2-dataset-nonretracted/A.Fib'  # Path to the folder for A. Fib images
sinus_folder = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V2-dataset-nonretracted/Sinus Rhythm'  # Path to the folder for Sinus Rhythm images
abnormal_folder = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V2-dataset-nonretracted/Abnormal'  # Path to the folder for Abnormal (not A. Fib) images

categorize_ecg_images(excel_path, images_path, afib_folder, sinus_folder, abnormal_folder)



import os
import json
from collections import defaultdict
import pandas as pd
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

# Update the path to the folder containing the JSON files
folder_path = '/content/drive/MyDrive/aub/fall 2024-2025/vip ai in med/testing llms for afib reasoning/V1Classified-dataset - retracted/afib'

# Ground truth definitions for AFIB
expected_responses = {
    "AFIB": {
        "Diagnosis": "AFIB",
        "Rhythm Regularity": "Irregularly Irregular",
        "P Waves": "Absent",
        "Baseline Activity": "Fibrillatory Waves",
        "Ventricular Rate": "Tachycardic",
        "QRS Complex Morphology": "Constant",
        "PR Interval": "Not Measurable"
    }
}

ground_truth_key = "AFIB"
ground_truth = expected_responses[ground_truth_key]

statistics = defaultdict(lambda: defaultdict(int))
feature_stats = defaultdict(lambda: defaultdict(list))
precision_scores = defaultdict(list)
recall_scores = defaultdict(list)
f1_scores = defaultdict(list)
error_rates = defaultdict(float)
confidence_intervals = defaultdict(lambda: (0, 0))

# Helper function to calculate confidence intervals
def calculate_confidence_interval(accuracy, total):
    if total > 0:
        z = 1.96  # 95% confidence interval
        p = accuracy / 100
        margin = z * np.sqrt((p * (1 - p)) / total)
        return max(0, p - margin) * 100, min(100, p + margin) * 100
    return 0, 0

def evaluate_response(json_data, ground_truth, features):
    comparison = {}
    for feature in features:
        comparison[feature] = json_data.get(feature, "Missing Value") == ground_truth.get(feature, "Missing Value")
    return comparison

valid_responses = 0
total_responses = 0
results = []

for filename in os.listdir(folder_path):
    if filename.endswith(".json"):
        total_responses += 1
        file_path = os.path.join(folder_path, filename)

        with open(file_path, 'r') as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                continue

            if isinstance(data, dict) and "Diagnosis" in data:
                valid_responses += 1
                comparison = evaluate_response(data, ground_truth, ground_truth.keys())

                for feature, is_correct in comparison.items():
                    statistics[feature]["correct"] += is_correct
                    statistics[feature]["total"] += 1
                    feature_stats[feature][filename].append(is_correct)

                results.append({
                    "Filename": filename,
                    **comparison
                })

# Calculate additional metrics
for feature, counts in statistics.items():
    accuracy = counts["correct"] / counts["total"] * 100 if counts["total"] > 0 else 0
    error_rates[feature] = 100 - accuracy
    confidence_intervals[feature] = calculate_confidence_interval(accuracy, counts["total"])
    counts["accuracy"] = accuracy

df = pd.DataFrame(results)

# Compute precision, recall, and F1-score for each feature
for feature in ground_truth.keys():
    y_true = [ground_truth[feature]] * len(df)
    y_pred = df[feature].apply(lambda x: ground_truth[feature] if x else "Incorrect").tolist()
    precision = precision_score(y_true, y_pred, average='binary', zero_division=0, pos_label=ground_truth[feature])
    recall = recall_score(y_true, y_pred, average='binary', zero_division=0, pos_label=ground_truth[feature])
    f1 = f1_score(y_true, y_pred, average='binary', zero_division=0, pos_label=ground_truth[feature])

    precision_scores[feature].append(precision)
    recall_scores[feature].append(recall)
    f1_scores[feature].append(f1)

# Save results to CSV
output_folder = os.path.join(folder_path, f"{ground_truth_key}_Analysis")
os.makedirs(output_folder, exist_ok=True)

df.to_csv(os.path.join(output_folder, f"detailed_results_{ground_truth_key}.csv"), index=False)

# Visualization
# Feature-level accuracy
features = list(statistics.keys())
accuracies = [statistics[feature]["accuracy"] for feature in features]
error_rates_list = [error_rates[feature] for feature in features]

plt.figure(figsize=(10, 6))
plt.bar(features, accuracies, label="Accuracy (%)", alpha=0.7)
plt.bar(features, error_rates_list, label="Error Rate (%)", alpha=0.7)
plt.xlabel("Features")
plt.ylabel("Percentage (%)")
plt.title("Feature-Level Accuracy and Error Rate")
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(os.path.join(output_folder, "feature_accuracy_error_rate.png"))
plt.show()

# Precision, Recall, and F1-score per feature
precision_vals = [precision_scores[feature][0] * 100 for feature in features]
recall_vals = [recall_scores[feature][0] * 100 for feature in features]
f1_vals = [f1_scores[feature][0] * 100 for feature in features]

plt.figure(figsize=(10, 6))
bar_width = 0.25
x_indices = np.arange(len(features))

plt.bar(x_indices, precision_vals, bar_width, label="Precision (%)")
plt.bar(x_indices + bar_width, recall_vals, bar_width, label="Recall (%)")
plt.bar(x_indices + 2 * bar_width, f1_vals, bar_width, label="F1-Score (%)")

plt.xlabel("Features")
plt.ylabel("Percentage (%)")
plt.title("Precision, Recall, and F1-Score by Feature")
plt.xticks(x_indices + bar_width, features, rotation=45)
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(output_folder, "precision_recall_f1.png"))
plt.show()

# Print summary
print(f"Analysis for {ground_truth_key} Cases")
print("Feature-level Statistics:")
for feature, counts in statistics.items():
    print(f"{feature}: {counts['accuracy']:.2f}% accuracy, Error Rate: {error_rates[feature]:.2f}%, Confidence Interval: {confidence_intervals[feature]}")

print("\nPrecision, Recall, and F1-Score:")
for feature in ground_truth.keys():
    print(f"{feature}: Precision: {precision_scores[feature][0]:.2f}, Recall: {recall_scores[feature][0]:.2f}, F1-Score: {f1_scores[feature][0]:.2f}")